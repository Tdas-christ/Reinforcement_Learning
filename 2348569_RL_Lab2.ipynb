{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBZedzDzIc6xeFZYg8FLL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tdas-christ/Reinforcement_Learning/blob/main/2348569_RL_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lupdh1u8tyiZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class NonStationaryBandit:\n",
        "    def __init__(self, n_arms, window_size, epsilon=0.1):\n",
        "        self.n_arms = n_arms\n",
        "        self.window_size = window_size  # Sliding window for nonstationary environment\n",
        "        self.epsilon = epsilon\n",
        "        self.rewards_history = [[] for _ in range(n_arms)]  # Reward history for each arm\n",
        "        self.arm_counts = [0] * n_arms  # Number of times each arm has been pulled\n",
        "\n",
        "    def pull(self, arm, reward):\n",
        "        \"\"\"Update reward history and trim to sliding window size.\"\"\"\n",
        "        self.rewards_history[arm].append(reward)\n",
        "        if len(self.rewards_history[arm]) > self.window_size:\n",
        "            self.rewards_history[arm].pop(0)  # Remove oldest reward (sliding window)\n",
        "        self.arm_counts[arm] += 1\n",
        "\n",
        "    def choose_arm(self):\n",
        "        \"\"\"Choose an arm using Îµ-greedy strategy.\"\"\"\n",
        "        if random.random() < self.epsilon:\n",
        "            # Exploration: choose a random arm\n",
        "            return random.randint(0, self.n_arms - 1)\n",
        "        else:\n",
        "            # Exploitation: choose the arm with the highest average reward\n",
        "            avg_rewards = [np.mean(history) if history else 0 for history in self.rewards_history]\n",
        "            return np.argmax(avg_rewards)\n",
        "\n",
        "    def simulate(self, reward_functions, n_rounds):\n",
        "        \"\"\"Simulate the bandit pulling arms with nonstationary rewards.\"\"\"\n",
        "        total_rewards = 0\n",
        "        for _ in range(n_rounds):\n",
        "            chosen_arm = self.choose_arm()\n",
        "            # Get reward based on the provided reward function (which can change over time)\n",
        "            reward = reward_functions[chosen_arm]()\n",
        "            self.pull(chosen_arm, reward)\n",
        "            total_rewards += reward\n",
        "        return total_rewards\n",
        "\n",
        "# Define nonstationary reward functions for each arm\n",
        "def reward_arm_1():\n",
        "    # Reward drifts over time for arm 1\n",
        "    return np.random.normal(loc=np.sin(np.pi * np.random.random()), scale=1)\n",
        "\n",
        "def reward_arm_2():\n",
        "    # Reward for arm 2 changes with random fluctuations\n",
        "    return np.random.normal(loc=np.cos(np.pi * np.random.random()), scale=1)\n",
        "\n",
        "# Instantiate the nonstationary bandit with 2 arms and a sliding window size of 50\n",
        "bandit = NonStationaryBandit(n_arms=2, window_size=50, epsilon=0.1)\n",
        "\n",
        "# Define the reward functions for each arm (which can change over time)\n",
        "reward_functions = [reward_arm_1, reward_arm_2]\n",
        "\n",
        "# Simulate 1000 rounds\n",
        "total_rewards = bandit.simulate(reward_functions, n_rounds=1000)\n",
        "\n",
        "print(\"Total rewards after 1000 rounds:\", total_rewards)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\\\\(3\\mathrm{\\, N\\cdot s}\\\\)\n",
        "\n",
        "\n",
        "\\\\(3\\text{ \\frac{m}{s}}\\\\)\n",
        "\n",
        "\n",
        "\\\\(3\\text{ m/s}\\\\)\n",
        "\n",
        "\n",
        "\\\\(3\\text{ N\\cdot s}\\\\)\n",
        "\n",
        "\n",
        "\\\\(3\\mathrm{m/s}\\\\)\n",
        "\n"
      ],
      "metadata": {
        "id": "NeIiHOT5tzdd"
      }
    }
  ]
}